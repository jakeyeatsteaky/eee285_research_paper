\begin{titlepage}
    \begin{center}
        \vspace*{-20mm}
        \Huge
        \textbf{Data Flow Architecture: Benefits, Limitations and Future Applications}\\
         \large
        
        \vspace{0.5 cm}
        \textbf{
        Jake Baker (jacobwilliambaker@csus.edu) \\
        Jesse Harkness (jesseharkness@csus.edu)}
        \\ EEE285 - Micro-Computer System Design I
        \\INSERT/ACTUAL/DATE
        \vfill
        \vspace{1cm}
        \textbf{Abstract}\\
        Very little explanation is required to describe why the most prolific technology trends throughout history become so popular; from the adoption of Cloud-based data storage[1], to the micro-service architecture that supports 85\% of large organizations worldwide[2], the most popular technological advances are those which provide a clear path to profit, and a user-friendly method for implementing the technology.  Currently, the next ubiquitous technological advance is artificial intelligence (AI), and its ability to solve even the most complex problems through sheer brute force computation.  But this level of computation comes at a cost; increasing transistor density is no longer a feasible method for increasing compute power [3].  In contrast to the traditional CPU architecture relying on smaller and denser transistors, Data Flow Architecture (DFA) is a hardware design which maximizes compute potential by reducing data movement, and increasing work efficiency through highly specialized chips.  
\par
Companies like SambaNova are at the forefront of this hardware technology, creating chips which can support AI models with up to 5 trillion parameters [4]; however, in order for this impressive technology to become trending, manufacturers need to overcome a host of challenges blocking the next generation of AI fueled technology.  While the aforementioned processors at SambaNova are undoubtedly powerful, the lack of software support for most data flow architectures is creating a void between what's possible, versus what's practical.  Data Flow Architectures have the potential to provide immense compute capability for the field of AI and Machine Learning; however the fledgling software ecosystem to support this architecture creates a unique challenge for its practical use, thus stifling its potential mass consumerization.  More traditional computer architectures, like the Von Neumann CPU architecture and GPU architecture, have a rich software backbone making it a more pragmatic choice for many companies with products the AI/ML space.  Overcoming the current nascent software landscape will be a necessary step in the future of data flow architectures for AI/ML applications. 
        
        \vspace{0.4cm}
        
        \includegraphics[width=0.4\textwidth]{Picture Files/1200px-California_State_University,_Sacramento_seal.svg.png}
        \large
        \par
        Dr. Vadhva\\
        College of Engineering\\
        INSERT/ACTUAL/DATE\\
    \end{center}
\end{titlepage}